# -*- coding: utf-8 -*-
"""
Created on Sat Oct 11 11:13:03 2025

@author: Yong Jin Park
"""

from pathlib import Path
import geopandas as gpd
import folium
from shapely.geometry import LineString, Point, Polygon
import branca.colormap as cm

import pandas as pd
from datetime import datetime
from io import StringIO
from tqdm import tqdm
import geopandas as gpd
import folium
import matplotlib.pyplot as plt
import os
import numpy as np
import json 
from shapely.geometry import Polygon
from shapely.geometry import MultiPolygon
from shapely.geometry import box
from shapely.strtree import STRtree
import gc
from pathlib import Path
# import os
from glob import glob
import time
from line_profiler import profile
# from sqlalchemy import create_engine
import psycopg2
import logging, psutil

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

plt.rc('font', family='NanumGothic')

#%%
# ê¸°ì¤€ ê²½ë¡œ ë° ê²€ìƒ‰ íŒ¨í„´ ì„¤ì •
BASE_PATH = Path.cwd()
# MODIFIED: '251011' í´ë”ë¥¼ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ë„ë¡ íŒ¨í„´ ë³µì›
# SEARCH_PATTERN = 
YEAR = 2025

# --- 2. ë§í¬(Links) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
# ì´ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤.
try:
    logging.info("ì›ë³¸ ë§í¬ Shapefileì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    # ì‚¬ìš©ìžì˜ í™˜ê²½ì— ë§žê²Œ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    links_shp_path = "/data1/DTG/2023_1/JB/JBLINK.shp"
    links = gpd.read_file(links_shp_path, engine='pyogrio', columns=['LINK_ID', "ROAD_RANK", 'geometry'])
    
    logging.info("ROAD_RANKê°€ '103'ì¸ ë§í¬ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.")
    links103_ids = links[links['ROAD_RANK'] == "103"]['LINK_ID'].tolist()
    links_filtered = links[links['LINK_ID'].isin(links103_ids)].copy()
    logging.info(f"ì´ {len(links_filtered)}ê°œì˜ '103' ë“±ê¸‰ ë§í¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    logging.error(f"ë§í¬ Shapefile ë¡œë“œ ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    links_filtered = None

#%%
# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
#í•´ë‹¹ íŒŒì´ì¬ íŒŒì¼ì´ ìžˆëŠ” í•˜ìœ„ í´ë”ë¥¼ ëª¨ë‘ ì°¾ì•„ì„œ "dtgsum_link_2025_FINAL_RESULT.geoparquet" íŒŒì¼ì„ ì°¾ì•„ì„œ ëª¨ë‘ í•©ì¹˜ëŠ” ì½”ë“œë¡œ ìˆ˜ì •í•´ì•¼í•¨
# input_path = Path(r"????")
# input_path = Path(os.getcwd())
input_path = Path.cwd()
# intermediate_files = glob(os.path.join(input_path, f"dtgsum_link_2025_*.geoparquet"))
# intermediate_files = glob(os.path.join(input_path, f"251011/dtgsum_link_2025_*.geoparquet"))
search_pattern = "dps_RES0012522/output_JB/251004/251011/dtgsum_link_2025_FINAL_RESULT.geoparquet"

intermediate_files = list(input_path.glob(search_pattern))
print(f"'{search_pattern}' íŒ¨í„´ìœ¼ë¡œ ì´ {len(intermediate_files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

print(intermediate_files)
#dtgsum_link_2025_051_002
# intermediate_files = glob(os.path.join(input_path, f"dtgsum_link_2025_FINAL_RESULT.geoparquet"))

if not intermediate_files:
    raise FileNotFoundError(f"ì§€ì •ëœ ê²½ë¡œì— GeoParquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")

# --- íš¨ìœ¨ì ìœ¼ë¡œ ê°œì„ ëœ ë°ì´í„° ì§‘ê³„ ë¶€ë¶„ ---
agg_results = []
# geometry ì •ë³´ë¥¼ ë‹´ì•„ë‘˜ GeoDataFrame (ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ì´ˆê¸°í™”)
geometry_gdf = gpd.read_parquet(intermediate_files[0])[['LINK_ID', 'geometry']].drop_duplicates(subset=['LINK_ID']).set_index('LINK_ID')

for f in tqdm(intermediate_files, desc="Aggregating chunk files"):
    chunk_df = pd.read_parquet(f, columns=['LINK_ID', 'vehicle_count', 'VLM'])
    current_agg = chunk_df.groupby('LINK_ID')[['vehicle_count', 'VLM']].sum()
    agg_results.append(current_agg)

logging.info("ëª¨ë“  íŒŒì¼ ì§‘ê³„ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤...")
# ëª¨ë“  ì§‘ê³„ ê²°ê³¼ë¥¼ í•œ ë²ˆì— í•©ì‚°
final_agg_df = pd.concat(agg_results).groupby('LINK_ID').sum().reset_index()

logging.info("ì§‘ê³„ ì™„ë£Œ. Geometry ì •ë³´ì™€ ë³‘í•©ì„ ì‹œìž‘í•©ë‹ˆë‹¤.")
# ì§‘ê³„ ê²°ê³¼ì™€ Geometry ì •ë³´ë¥¼ LINK_ID ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
# ì´ì œ final_gdfëŠ” GeoDataFrameì´ ë©ë‹ˆë‹¤.
final_gdf = gpd.GeoDataFrame(final_agg_df.merge(geometry_gdf, on='LINK_ID', how='inner'))

links = gpd.read_file(r"/data1/DTG/2023_1/JB/JBLINK.shp", engine='pyogrio',columns=['LINK_ID',"ROAD_RANK",'geometry'])
# links = gpd.read_file(r"D:\NIPA_GIT\TAMSPython\TAMSPython\JB\JBLINK.shp", engine='pyogrio',columns=['LINK_ID',"ROAD_RANK",'geometry'])
links103 = links[links['ROAD_RANK']=="103"]['LINK_ID'].tolist()
links103 = links[links['LINK_ID'].isin(links103)]

# ìµœì¢… ì§‘ê³„ ê²°ê³¼ì— ë§í¬ì˜ geometry ì •ë³´ ê²°í•©
links_geom = links103[['LINK_ID', 'geometry']].drop_duplicates(subset=['LINK_ID'])
final_merged_gdf = pd.merge(links_geom, final_gdf, on='LINK_ID', how='left')

# ì§‘ê³„ë˜ì§€ ì•Šì€ ë§í¬ëŠ” 0ìœ¼ë¡œ ì±„ìš°ê¸°
final_merged_gdf['vehicle_count'] = final_merged_gdf['vehicle_count'].fillna(0).astype(int)
final_merged_gdf['VLM'] = final_merged_gdf['VLM'].fillna(0).astype(int)
print(final_merged_gdf.columns)

del final_merged_gdf['geometry_y']
final_merged_gdf = final_merged_gdf.rename(columns={'geometry_x': 'geometry'})
print(final_merged_gdf.columns)
final_merged_gdf.set_geometry("geometry")

final_merged_gdf = final_merged_gdf.set_crs(epsg=32652, allow_override=True)
# --- ì½”ë“œ ì‹¤í–‰ ë¶€ë¶„ ---
# 'ratio' ì»¬ëŸ¼ ê³„ì‚°
final_merged_gdf['ratio'] = np.where(
    final_merged_gdf['VLM'] == 0, 
    0, 
    (final_merged_gdf['vehicle_count'] / final_merged_gdf['VLM']) * 100
)

final_merged_gdf['ratio'] = final_merged_gdf['ratio'].round(1)
print(final_merged_gdf.info())

print(final_merged_gdf.head())
print(final_merged_gdf.tail())

#%%
output_path_excel = os.path.join(input_path, "final_merged_gdf2ì‹œê°„ì´ìƒ.xlsx")
final_merged_gdf.to_excel(output_path_excel, index=False)

output_path_gdf = os.path.join(input_path, "final_merged_gdf2ì‹œê°„ì´ìƒ.geoparquet")
final_merged_gdf.to_parquet(output_path_gdf, engine='pyarrow', compression='snappy', index=False)

#%%
# --- ì§€ë„ ìƒì„± í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ, ê·¸ëŒ€ë¡œ ì‚¬ìš©) ---
def create_map(gdf, column_name, output_filename):
    """
    ì£¼ì–´ì§„ GeoDataFrameê³¼ ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ Folium ì§€ë„ë¥¼ ìƒì„±í•˜ê³  HTML íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.
    (í•¨ìˆ˜ ë‚´ìš©ì€ ì›ë³¸ê³¼ ë™ì¼)
    """
    try:
        print(f"'{column_name}'ì— ëŒ€í•œ ì§€ë„ ìƒì„±ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")
        gdf_copy = gdf.copy()
        gdf_copy[column_name] = gdf_copy[column_name].fillna(0)

        if gdf_copy.crs is None:
            gdf_copy = gdf_copy.set_crs(epsg=32652, allow_override=True)

        gdf_copy = gdf_copy.to_crs(epsg=4326)
        center = ((gdf_copy.total_bounds[1] + gdf_copy.total_bounds[3]) / 2.0,
                  (gdf_copy.total_bounds[0] + gdf_copy.total_bounds[2]) / 2.0)
        
        m = folium.Map(location=center, zoom_start=11, control_scale=True)

        folium.TileLayer(
            tiles="https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}",
            attr="Esri",
            name="Esri Satellite",
            overlay=False,
            control=True
        ).add_to(m)
        
        valid_data = gdf_copy[gdf_copy[column_name] >= 0][column_name]
        vmin = valid_data.min() if not valid_data.empty else 0
        vmax = valid_data.max() if not valid_data.empty else 1

        colormap = cm.LinearColormap(colors=["black", "blue", "red"], vmin=vmin, vmax=vmax, caption=column_name)
        
        def style_fn(feature):
            value = feature['properties'].get(column_name, 0)
            try:
                value = float(value)
            except (ValueError, TypeError):
                value = 0.0
            
            if value < 0:
                return {'fillOpacity': 0, 'weight': 0}
            else:
                return {'color': colormap(value), 'weight': 3, 'opacity': 0.8}
        
        folium.GeoJson(
            gdf_copy,
            name=column_name,
            style_function=style_fn,
            tooltip=folium.features.GeoJsonTooltip(
                fields=["LINK_ID", column_name], 
                aliases=["LINK_ID:", f"{column_name}:"]
            ),
            overlay=True,
            control=True
        ).add_to(m)
        
        colormap.add_to(m)
        folium.LayerControl().add_to(m)
        
        m.save(output_filename)
        print(f"âœ… ì„±ê³µ! ì§€ë„ë¥¼ '{output_filename}' íŒŒì¼ë¡œ ì €ìž¥í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: '{column_name}' ì§€ë„ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({repr(e)})")


# ê° ì»¬ëŸ¼ì— ëŒ€í•œ ì§€ë„ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (ì´ì œ GeoDataFrameì¸ final_gdfë¥¼ ì „ë‹¬)
create_map(final_merged_gdf, 'vehicle_count', 'map_2ì‹œê°„ì´ìƒì£¼í–‰ì°¨ëŸ‰ëŒ€ìˆ˜.html')
create_map(final_merged_gdf, 'VLM', 'map_2ì‹œê°„ì´ìƒì „ì²´êµí†µëŸ‰.html')
create_map(final_merged_gdf, 'ratio', 'map_2ì‹œê°„ì´ìƒratio.html')

print("\nðŸŽ‰ ëª¨ë“  ì§€ë„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

#%%
# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
#í•´ë‹¹ íŒŒì´ì¬ íŒŒì¼ì´ ìžˆëŠ” í•˜ìœ„ í´ë”ë¥¼ ëª¨ë‘ ì°¾ì•„ì„œ "dtgsum_link_2025_FINAL_RESULT.geoparquet" íŒŒì¼ì„ ì°¾ì•„ì„œ ëª¨ë‘ í•©ì¹˜ëŠ” ì½”ë“œë¡œ ìˆ˜ì •í•´ì•¼í•¨
# input_path = Path(r"????")
# input_path = Path(os.getcwd())
input_path = Path.cwd()
# intermediate_files = glob(os.path.join(input_path, f"dtgsum_link_2025_*.geoparquet"))
# intermediate_files = glob(os.path.join(input_path, f"251011/dtgsum_link_2025_*.geoparquet"))
# search_pattern = "**/251012/dtgsum_link_2025_*.geoparquet"
search_pattern = "dps_RES0012522/output_JB/251004/251012/dtgsum_link_2025_FINAL_RESULT.geoparquet"

intermediate_files = list(input_path.glob(search_pattern))
print(f"'{search_pattern}' íŒ¨í„´ìœ¼ë¡œ ì´ {len(intermediate_files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

print(intermediate_files)
#dtgsum_link_2025_051_002
# intermediate_files = glob(os.path.join(input_path, f"dtgsum_link_2025_FINAL_RESULT.geoparquet"))

if not intermediate_files:
    raise FileNotFoundError(f"ì§€ì •ëœ ê²½ë¡œì— GeoParquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")

# --- íš¨ìœ¨ì ìœ¼ë¡œ ê°œì„ ëœ ë°ì´í„° ì§‘ê³„ ë¶€ë¶„ ---
agg_results = []
# geometry ì •ë³´ë¥¼ ë‹´ì•„ë‘˜ GeoDataFrame (ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ì´ˆê¸°í™”)
geometry_gdf = gpd.read_parquet(intermediate_files[0])[['LINK_ID', 'geometry']].drop_duplicates(subset=['LINK_ID']).set_index('LINK_ID')

for f in tqdm(intermediate_files, desc="Aggregating chunk files"):
    chunk_df = pd.read_parquet(f, columns=['LINK_ID', 'vehicle_count', 'VLM'])
    current_agg = chunk_df.groupby('LINK_ID')[['vehicle_count', 'VLM']].sum()
    agg_results.append(current_agg)

logging.info("ëª¨ë“  íŒŒì¼ ì§‘ê³„ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤...")
# ëª¨ë“  ì§‘ê³„ ê²°ê³¼ë¥¼ í•œ ë²ˆì— í•©ì‚°
final_agg_df = pd.concat(agg_results).groupby('LINK_ID').sum().reset_index()

logging.info("ì§‘ê³„ ì™„ë£Œ. Geometry ì •ë³´ì™€ ë³‘í•©ì„ ì‹œìž‘í•©ë‹ˆë‹¤.")
# ì§‘ê³„ ê²°ê³¼ì™€ Geometry ì •ë³´ë¥¼ LINK_ID ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
# ì´ì œ final_gdfëŠ” GeoDataFrameì´ ë©ë‹ˆë‹¤.
final_gdf = gpd.GeoDataFrame(final_agg_df.merge(geometry_gdf, on='LINK_ID', how='inner'))

links = gpd.read_file(r"/data1/DTG/2023_1/JB/JBLINK.shp", engine='pyogrio',columns=['LINK_ID',"ROAD_RANK",'geometry'])
# links = gpd.read_file(r"D:\NIPA_GIT\TAMSPython\TAMSPython\JB\JBLINK.shp", engine='pyogrio',columns=['LINK_ID',"ROAD_RANK",'geometry'])
links103 = links[links['ROAD_RANK']=="103"]['LINK_ID'].tolist()
links103 = links[links['LINK_ID'].isin(links103)]

# ìµœì¢… ì§‘ê³„ ê²°ê³¼ì— ë§í¬ì˜ geometry ì •ë³´ ê²°í•©
links_geom = links103[['LINK_ID', 'geometry']].drop_duplicates(subset=['LINK_ID'])
final_merged_gdf = pd.merge(links_geom, final_gdf, on='LINK_ID', how='left')

# ì§‘ê³„ë˜ì§€ ì•Šì€ ë§í¬ëŠ” 0ìœ¼ë¡œ ì±„ìš°ê¸°
final_merged_gdf['vehicle_count'] = final_merged_gdf['vehicle_count'].fillna(0).astype(int)
final_merged_gdf['VLM'] = final_merged_gdf['VLM'].fillna(0).astype(int)
print(final_merged_gdf.columns)

del final_merged_gdf['geometry_y']
final_merged_gdf = final_merged_gdf.rename(columns={'geometry_x': 'geometry'})
print(final_merged_gdf.columns)
final_merged_gdf.set_geometry("geometry")

final_merged_gdf = final_merged_gdf.set_crs(epsg=32652, allow_override=True)
# --- ì½”ë“œ ì‹¤í–‰ ë¶€ë¶„ ---
# 'ratio' ì»¬ëŸ¼ ê³„ì‚°
final_merged_gdf['ratio'] = np.where(
    final_merged_gdf['VLM'] == 0, 
    0, 
    (final_merged_gdf['vehicle_count'] / final_merged_gdf['VLM']) * 100
)

final_merged_gdf['ratio'] = final_merged_gdf['ratio'].round(1)
print(final_merged_gdf.info())

print(final_merged_gdf.head())
print(final_merged_gdf.tail())

#%%
output_path_excel = os.path.join(input_path, "final_merged_gdf2ì‹œê°„30ë¶„ì´ìƒ.xlsx")
final_merged_gdf.to_excel(output_path_excel, index=False)

output_path_gdf = os.path.join(input_path, "final_merged_gdf2ì‹œê°„30ë¶„ì´ìƒ.geoparquet")
final_merged_gdf.to_parquet(output_path_gdf, engine='pyarrow', compression='snappy', index=False)

#%%

# ê° ì»¬ëŸ¼ì— ëŒ€í•œ ì§€ë„ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (ì´ì œ GeoDataFrameì¸ final_gdfë¥¼ ì „ë‹¬)
create_map(final_merged_gdf, 'vehicle_count', 'map_2ì‹œê°„30ë¶„ì´ìƒì£¼í–‰ì°¨ëŸ‰ëŒ€ìˆ˜.html')
create_map(final_merged_gdf, 'VLM', 'map_2ì‹œê°„30ë¶„ì´ìƒ_ì „ì²´êµí†µëŸ‰.html')
create_map(final_merged_gdf, 'ratio', 'map_2ì‹œê°„30ë¶„ì´ìƒ_ratio.html')

print("\nðŸŽ‰ ëª¨ë“  ì§€ë„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
